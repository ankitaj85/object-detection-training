{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplaod data to gs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://data\\TEST\\default.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file://data\\TEST\\label_map.pbtxt [Content-Type=application/octet-stream]...\n",
      "/ [0/4 files][    0.0 B/  1.2 MiB]   0% Done                                    \n",
      "/ [0/4 files][    0.0 B/  1.2 MiB]   0% Done                                    \n",
      "Copying file://data\\TRAIN\\label_map.pbtxt [Content-Type=application/octet-stream]...\n",
      "/ [0/4 files][    0.0 B/  1.2 MiB]   0% Done                                    \n",
      "Copying file://data\\TRAIN\\default.tfrecord [Content-Type=application/octet-stream]...\n",
      "/ [0/4 files][    0.0 B/  1.2 MiB]   0% Done                                    \n",
      "/ [1/4 files][  1.2 MiB/  1.2 MiB]  99% Done                                    \n",
      "-\n",
      "- [2/4 files][  1.2 MiB/  1.2 MiB]  99% Done                                    \n",
      "- [3/4 files][  1.2 MiB/  1.2 MiB]  99% Done                                    \n",
      "- [4/4 files][  1.2 MiB/  1.2 MiB] 100% Done                                    \n",
      "\n",
      "Operation completed over 4 objects/1.2 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r  data gs://object-detection-pipeline-demo/workspace/local/annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create script files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.sh\n",
    "git clone https://github.com/ankitaj85/tensorflow-object-detection-api-setup.git\n",
    "cd tensorflow-object-detection-api-setup\n",
    "chmod +x setup-object-detection-api-tf-2-4-0.sh\n",
    "./setup-object-detection-api-tf-2-4-0.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7_1xVJSpx7k"
   },
   "source": [
    "# List of Models\n",
    "Model name                                                                                                                                                                  | Speed (ms) | COCO mAP | Outputs\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------: | :----------: | :-----:\n",
    "[CenterNet HourGlass104 512x512](http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_512x512_coco17_tpu-8.tar.gz)                    | 70         | 41.9           | Boxes\n",
    "[CenterNet HourGlass104 Keypoints 512x512](http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_512x512_kpts_coco17_tpu-32.tar.gz)                    | 76         | 40.0/61.4           | Boxes/Keypoints\n",
    "[CenterNet HourGlass104 1024x1024](http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_1024x1024_coco17_tpu-32.tar.gz)               | 197       | 44.5           | Boxes\n",
    "[CenterNet HourGlass104 Keypoints 1024x1024](http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_1024x1024_kpts_coco17_tpu-32.tar.gz)               | 211       | 42.8/64.5          | Boxes/Keypoints\n",
    "[CenterNet Resnet50 V1 FPN 512x512](http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v1_fpn_512x512_coco17_tpu-8.tar.gz)     | 27         | 31.2           | Boxes\n",
    "[CenterNet Resnet50 V1 FPN Keypoints 512x512](http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8.tar.gz)     | 30         | 29.3/50.7         | Boxes/Keypoints\n",
    "[CenterNet Resnet101 V1 FPN 512x512](http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8.tar.gz)     | 34         | 34.2           | Boxes\n",
    "[CenterNet Resnet50 V2 512x512](http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v2_512x512_coco17_tpu-8.tar.gz)     | 27         | 29.5           | Boxes\n",
    "[CenterNet Resnet50 V2 Keypoints 512x512](http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v2_512x512_kpts_coco17_tpu-8.tar.gz)     | 30         | 27.6/48.2           | Boxes/Keypoints\n",
    "[EfficientDet D0 512x512](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz)                                  | 39         | 33.6           | Boxes\n",
    "[EfficientDet D1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz)                                  | 54         | 38.4           | Boxes\n",
    "[EfficientDet D2 768x768](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz)                                  | 67         | 41.8           | Boxes\n",
    "[EfficientDet D3 896x896](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d3_coco17_tpu-32.tar.gz)                                  | 95         | 45.4           | Boxes\n",
    "[EfficientDet D4 1024x1024](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d4_coco17_tpu-32.tar.gz)                              | 133         | 48.5           | Boxes\n",
    "[EfficientDet D5 1280x1280](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d5_coco17_tpu-32.tar.gz)                             | 222         | 49.7           | Boxes\n",
    "[EfficientDet D6 1280x1280](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d6_coco17_tpu-32.tar.gz)                             | 268         | 50.5           | Boxes\n",
    "[EfficientDet D7 1536x1536](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d7_coco17_tpu-32.tar.gz)                             | 325         | 51.2           | Boxes\n",
    "[SSD MobileNet v2 320x320](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz)                                |19         | 20.2           | Boxes\n",
    "[SSD MobileNet V1 FPN 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz)                        | 48        | 29.1           | Boxes\n",
    "[SSD MobileNet V2 FPNLite 320x320](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz)                | 22         | 22.2           | Boxes\n",
    "[SSD MobileNet V2 FPNLite 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz)                | 39         | 28.2           | Boxes\n",
    "[SSD ResNet50 V1 FPN 640x640 (RetinaNet50)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz)                          | 46         | 34.3           | Boxes\n",
    "[SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz)                      | 87         | 38.3           | Boxes\n",
    "[SSD ResNet101 V1 FPN 640x640 (RetinaNet101)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz)                        | 57         | 35.6           | Boxes\n",
    "[SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8.tar.gz)                    | 104        | 39.5           | Boxes\n",
    "[SSD ResNet152 V1 FPN 640x640 (RetinaNet152)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.tar.gz)                        | 80         | 35.4           | Boxes\n",
    "[SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.tar.gz)                    | 111        | 39.6           | Boxes\n",
    "[Faster R-CNN ResNet50 V1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz)                 | 53         | 29.3           | Boxes\n",
    "[Faster R-CNN ResNet50 V1 1024x1024](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.tar.gz)             | 65         | 31.0           | Boxes\n",
    "[Faster R-CNN ResNet50 V1 800x1333](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.tar.gz)               | 65         | 31.6           | Boxes\n",
    "[Faster R-CNN ResNet101 V1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz)               |    55      | 31.8           | Boxes\n",
    "[Faster R-CNN ResNet101 V1 1024x1024](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz)           | 72         | 37.1           | Boxes\n",
    "[Faster R-CNN ResNet101 V1 800x1333](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8.tar.gz)             | 77         | 36.6           | Boxes\n",
    "[Faster R-CNN ResNet152 V1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz)               | 64         | 32.4           | Boxes\n",
    "[Faster R-CNN ResNet152 V1 1024x1024](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz)           | 85         | 37.6           | Boxes\n",
    "[Faster R-CNN ResNet152 V1 800x1333](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8.tar.gz)             | 101         | 37.4           | Boxes\n",
    "[Faster R-CNN Inception ResNet V2 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz)             | 206         | 37.7           | Boxes\n",
    "[Faster R-CNN Inception ResNet V2 1024x1024](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz)             | 236         | 38.7           | Boxes\n",
    "[Mask R-CNN Inception ResNet V2 1024x1024](http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz) |    301      | 39.0/34.6           | Boxes/Masks\n",
    "[ExtremeNet](http://download.tensorflow.org/models/object_detection/tf2/20200711/extremenet.tar.gz)                                                                         | --         | --           | Boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDri49I3px7m",
    "outputId": "a512105a-3af5-45af-f984-2c9ee283e659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting download_model.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile download_model.sh\n",
    "# Download the checkpoint and put it into models/research/object_detection/test_data/\n",
    "model_display_name=ssd_mobilenet_v1_fpn_640x640_coco17_tpu_8\n",
    "DOWNLOAD_PATH=~/TensorFlow/workspace/local/pre-trained-raw/\n",
    "EXTRACT_PATH=~/TensorFlow/workspace/local/pre-trained-models\n",
    "echo ${DOWNLOAD_PATH}\n",
    "echo $EXTRACT_PATH\n",
    "if [ $model_display_name==ssd_mobilenet_v1_fpn_640x640_coco17_tpu_8 ]\n",
    "then \n",
    "  if [ -f \"$DOWNLOAD_PATH/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\" ] \n",
    "  then\n",
    "    echo File Exist - Below Find List of Models\n",
    "    ls $DOWNLOAD_PATH\n",
    "  else\n",
    "    wget  -q http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz -P ${DOWNLOAD_PATH}\n",
    "    tar -xf ${DOWNLOAD_PATH}/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz -C $EXTRACT_PATH\n",
    "  fi  \n",
    "else\n",
    "   echo \"a is not equal to b\"\n",
    "fi\n",
    "# https://cloud.google.com/storage/docs/gsutil/commands/cp#:~:text=The%20gsutil%20cp%20command%20allows%20you%20to%20copy,can%20also%20download%20text%20files%20from%20a%20bucket:\n",
    "gsutil -m cp -r  ~/TensorFlow/workspace/ gs://object-detection-pipeline-demo\n",
    "#!mv centernet_hg104_512x512_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "# define path \n",
    "\n",
    "FINE_TUNE_CHECKPOINT_TYPE : 'detection'\n",
    "FINE_TUNE_CHECKPOINT : gs://object-detection-pipeline-demo/workspace/local/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\n",
    "TRAIN_TFRECORD : gs://object-detection-pipeline-demo/workspace/local/annotations/TRAIN/default.tfrecord\n",
    "TEST_TFRECORD : gs://object-detection-pipeline-demo/workspace/local/annotations/TEST/default.tfrecord\n",
    "CONFIG_PATH : gs://object-detection-pipeline-demo/workspace/local/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
    "LABEL_MAP : gs://object-detection-pipeline-demo/workspace/local/annotations/TRAIN/label_map.pbtxt\n",
    "NUM_CLASSES : 2\n",
    "BATCH_SIZE : 10\n",
    "NUM_STEPS : 10\n",
    "LR_TOTAL_STEPS : 10\n",
    "LR_WARMUP_STEPS : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8xFK18E-px7m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pipeline_config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline_config.py\n",
    "# Configure pipeline.config\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\",'r') as infile:\n",
    "    config = yaml.load(infile.read(), Loader=yaml.SafeLoader)\n",
    "\n",
    "FINE_TUNE_CHECKPOINT_TYPE = config[\"FINE_TUNE_CHECKPOINT_TYPE\"]\n",
    "FINE_TUNE_CHECKPOINT      = config[\"FINE_TUNE_CHECKPOINT\"]\n",
    "TRAIN_TFRECORD            = [config[\"TRAIN_TFRECORD\"]]\n",
    "TEST_TFRECORD             = [config[\"TEST_TFRECORD\"]]\n",
    "CONFIG_PATH               = config[\"CONFIG_PATH\"]\n",
    "NUM_CLASSES               = config[\"NUM_CLASSES\"]\n",
    "BATCH_SIZE                = config[\"BATCH_SIZE\"]\n",
    "LABEL_MAP                 = config[\"LABEL_MAP\"]\n",
    "NUM_STEPS                 = config[\"NUM_STEPS\"]\n",
    "LR_TOTAL_STEPS            = config[\"LR_TOTAL_STEPS\"] \n",
    "LR_WARMUP_STEPS           = config[\"LR_WARMUP_STEPS\"] \n",
    "\n",
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "import object_detection\n",
    "from object_detection.protos import pipeline_pb2\n",
    "pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline)     \n",
    "\n",
    "pipeline.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.total_steps=LR_TOTAL_STEPS \n",
    "pipeline.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.warmup_steps=LR_WARMUP_STEPS\n",
    "pipeline.train_config.fine_tune_checkpoint = FINE_TUNE_CHECKPOINT\n",
    "pipeline.train_config.fine_tune_checkpoint_type = FINE_TUNE_CHECKPOINT_TYPE\n",
    "pipeline.train_config.batch_size=BATCH_SIZE \n",
    "pipeline.train_config.num_steps=NUM_STEPS               \n",
    "pipeline.model.ssd.num_classes = NUM_CLASSES\n",
    "\n",
    "# TRAIN INPUT PATH CONFIGURATION\n",
    "pipeline.train_input_reader.tf_record_input_reader.input_path[:] = TRAIN_TFRECORD # it's a repeated field \n",
    "pipeline.train_input_reader.label_map_path = LABEL_MAP\n",
    "\n",
    "# TEST INPUT PATH CONFIGURATION\n",
    "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[:] = TEST_TFRECORD # it's a repeated field \n",
    "pipeline.eval_input_reader[0].label_map_path = LABEL_MAP\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                       \n",
    "    f.write(config_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1XSROzGpx7n",
    "outputId": "234808df-e340-4693-8cbb-0280698aa078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting start_training.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile start_training.sh \n",
    "cd ~/TensorFlow/models/research \n",
    "PIPELINE_CONFIG_PATH=gs://object-detection-pipeline-demo/workspace/local/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
    "MODEL_DIR=gs://object-detection-pipeline-demo/workspace/local/model-checkpoints/3\n",
    "NUM_TRAIN_STEPS=10000\n",
    "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
    "python3 object_detection/model_main_tf2.py \\\n",
    "  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n",
    "  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n",
    "  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
    "  --alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUDxwXBcSHWu"
   },
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZgK_Ybkpx7n",
    "outputId": "2cf62284-4c61-4633-cd27-9952caa24bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting export_model.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile export_model.sh\n",
    "cd ~/TensorFlow/models/research \n",
    "CONFIG_PATH=gs://object-detection-pipeline-demo/workspace/local/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
    "MODEL_DIR=gs://object-detection-pipeline-demo/workspace/local/model-checkpoints/3\n",
    "EXPORT_MODEL=gs://object-detection-pipeline-demo/workspace/local/exported-models/3\n",
    "python3 object_detection/exporter_main_v2.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path $CONFIG_PATH \\\n",
    "    --trained_checkpoint_dir $MODEL_DIR \\\n",
    "    --output_directory $EXPORT_MODEL\n",
    "    #--config_override \" \\\n",
    "    #      model{ \\\n",
    "    #        faster_rcnn { \\\n",
    "    #         second_stage_post_processing { \\\n",
    "    #          batch_non_max_suppression { \\\n",
    "    #           score_threshold: 0.5 \\\n",
    "    #         } \\\n",
    "    #       } \\\n",
    "    #     } \\\n",
    "    #  }\"\n",
    "\n",
    "#If side inputs are desired, the following arguments could be appended\n",
    "#(the example below is for Context R-CNN).\n",
    "#   --use_side_inputs True \\\n",
    "#   --side_input_shapes 1,2000,2057/1 \\\n",
    "#   --side_input_names context_features,valid_context_size \\\n",
    "#   --side_input_types tf.float32,tf.int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Code Commit to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in training.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 96880bd] all file updated\n",
      " 5 files changed, 452 insertions(+), 650 deletions(-)\n",
      " rewrite training.ipynb (98%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/ankitaj85/object-detection-training.git\n",
      "   6b4bf7d..96880bd  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"all file updated\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
